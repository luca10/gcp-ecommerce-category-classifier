{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e663b48-a7fe-4367-bcd5-4214df4a7b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativo di download...\n",
      "SUCCESS: File scaricato.\n",
      "\n",
      "ERRORE FINALE: Expected 10 fields in line 6044, saw 11. Il file è irrimediabilmente malformato.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "# Importazione necessaria per il parametro quoting\n",
    "import csv \n",
    "\n",
    "# --- CONFIGURAZIONE (Immagino che questi siano corretti) ---\n",
    "BUCKET_NAME = \"data-science-project-luca-october-2025\" \n",
    "GCS_FILE_PATH = \"styles.csv\"       \n",
    "LOCAL_DOWNLOAD_PATH = \"styles_local.csv\" \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# 1. DOWNLOAD (come prima)\n",
    "try:\n",
    "    print(\"Tentativo di download...\")\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    blob = bucket.blob(GCS_FILE_PATH)\n",
    "    blob.download_to_filename(LOCAL_DOWNLOAD_PATH)\n",
    "    print(\"SUCCESS: File scaricato.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERRORE di Download GCS: {e}\")\n",
    "\n",
    "\n",
    "# 2. CARICAMENTO PANDAS CON GESTIONE ERRORI\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        LOCAL_DOWNLOAD_PATH, \n",
    "        sep=',',               \n",
    "        engine='python',       \n",
    "        encoding=\"ISO-8859-1\",\n",
    "        # PARAMETRO RISOLUTIVO: Forza Pandas a ignorare i problemi di citazione\n",
    "        quoting=csv.QUOTE_NONE \n",
    "    )\n",
    "    \n",
    "    print(\"\\nSUCCESS: Caricamento riuscito con forzatura CSV.\")\n",
    "    print(f\"Righe: {len(df)}, Colonne: {len(df.columns)}\")\n",
    "    print(\"Intestazioni delle Colonne:\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\nPrime 5 righe del DataFrame:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRORE FINALE: {e}. Il file è irrimediabilmente malformato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a68e98-ed55-492b-94b5-de7ad56c51d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tentativo di caricamento ignorando le righe malformate (on_bad_lines='skip')...\n",
      "\n",
      "✅ SUCCESS: DataFrame caricato, righe problematiche saltate.\n",
      "Righe finali nel DataFrame: 44424\n",
      "Intestazioni delle Colonne: ['id', 'gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'year', 'usage', 'productDisplayName']\n",
      "\n",
      "Prime 5 righe (finalmente!):\n",
      "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
      "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
      "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
      "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
      "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
      "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
      "\n",
      "     year   usage                             productDisplayName  \n",
      "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
      "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
      "2  2016.0  Casual                       Titan Women Silver Watch  \n",
      "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
      "4  2012.0  Casual                          Puma Men Grey T-shirt  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# ... (Omesso codice di download da GCS, che ha funzionato) ...\n",
    "LOCAL_DOWNLOAD_PATH = \"styles_local.csv\"\n",
    "\n",
    "# CARICAMENTO PANDAS CON GESTIONE DEGLI ERRORI AGGIORNATA\n",
    "try:\n",
    "    print(\"\\nTentativo di caricamento ignorando le righe malformate (on_bad_lines='skip')...\")\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        LOCAL_DOWNLOAD_PATH, \n",
    "        sep=',',               \n",
    "        engine='python',       \n",
    "        encoding=\"ISO-8859-1\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        # NUOVO PARAMETRO CHIAVE: ignora le righe che danno errore\n",
    "        on_bad_lines='skip' \n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ SUCCESS: DataFrame caricato, righe problematiche saltate.\")\n",
    "    print(f\"Righe finali nel DataFrame: {len(df)}\") \n",
    "    print(f\"Intestazioni delle Colonne: {df.columns.tolist()}\")\n",
    "    print(\"\\nPrime 5 righe (finalmente!):\")\n",
    "    print(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRORE CRITICO: Fallimento totale del caricamento. Passare al cambio di dataset. Errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc60e0a-80db-4288-8a3c-6135c31bcf80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Riepilogo del DataFrame ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44424 entries, 0 to 44423\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  44424 non-null  int64  \n",
      " 1   gender              44424 non-null  object \n",
      " 2   masterCategory      44424 non-null  object \n",
      " 3   subCategory         44424 non-null  object \n",
      " 4   articleType         44424 non-null  object \n",
      " 5   baseColour          44409 non-null  object \n",
      " 6   season              44403 non-null  object \n",
      " 7   year                44423 non-null  float64\n",
      " 8   usage               44107 non-null  object \n",
      " 9   productDisplayName  44417 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 3.4+ MB\n",
      "\n",
      "--- Percentuale di Valori Mancanti per Colonna ---\n",
      "usage                 0.713578\n",
      "season                0.047272\n",
      "baseColour            0.033766\n",
      "productDisplayName    0.015757\n",
      "year                  0.002251\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Panoramica rapida dei tipi di dati e dei valori mancanti\n",
    "print(\"--- Riepilogo del DataFrame ---\")\n",
    "df.info()\n",
    "\n",
    "# Controlla la distribuzione dei valori mancanti in percentuale\n",
    "print(\"\\n--- Percentuale di Valori Mancanti per Colonna ---\")\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percentage[missing_percentage > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453f636a-25e3-402a-b55c-28d0aae9201d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Distribuzione della Variabile Target: masterCategory ---\n",
      "masterCategory\n",
      "Apparel           21397\n",
      "Accessories       11274\n",
      "Footwear           9219\n",
      "Personal Care      2403\n",
      "Free Items          105\n",
      "Sporting Goods       25\n",
      "Home                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Controlla la distribuzione delle categorie principali\n",
    "print(\"\\n--- Distribuzione della Variabile Target: masterCategory ---\")\n",
    "print(df['masterCategory'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d29f551-58a1-4b18-abd9-b07797ad818e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe dopo aver rimosso le categorie con meno di 100 istanze: 44398\n",
      "\n",
      "--- Nuova Distribuzione del Target ---\n",
      "masterCategory\n",
      "Apparel          21397\n",
      "Accessories      11274\n",
      "Footwear          9219\n",
      "Personal Care     2403\n",
      "Free Items         105\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rimuovi le categorie con meno di 100 istanze per evitare rumore e bias eccessivi\n",
    "MIN_COUNT = 100 \n",
    "categories_to_keep = df['masterCategory'].value_counts()\n",
    "categories_to_keep = categories_to_keep[categories_to_keep >= MIN_COUNT].index\n",
    "\n",
    "df_ml = df[df['masterCategory'].isin(categories_to_keep)]\n",
    "\n",
    "print(f\"Righe dopo aver rimosso le categorie con meno di 100 istanze: {len(df_ml)}\")\n",
    "\n",
    "# Aggiorna la distribuzione del target\n",
    "print(\"\\n--- Nuova Distribuzione del Target ---\")\n",
    "print(df_ml['masterCategory'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e974c2-4db4-4949-b63c-7cff22c2bc4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero di colonne dopo l'encoding (molte di più!): 242\n",
      "Le prime nuove colonne: ['id', 'masterCategory', 'year', 'productDisplayName', 'gender_Girls', 'gender_Men', 'gender_Unisex', 'gender_Women', 'subCategory_Apparel Set', 'subCategory_Bags', 'subCategory_Bath and Body', 'subCategory_Beauty Accessories', 'subCategory_Belts', 'subCategory_Bottomwear', 'subCategory_Cufflinks']\n"
     ]
    }
   ],
   "source": [
    "# Seleziona le colonne categoriali per l'encoding\n",
    "categorical_cols = ['gender', 'subCategory', 'articleType', 'baseColour', 'season', 'usage']\n",
    "\n",
    "# Applica One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_ml, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(f\"\\nNumero di colonne dopo l'encoding (molte di più!): {len(df_encoded.columns)}\")\n",
    "print(\"Le prime nuove colonne:\", df_encoded.columns.tolist()[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d9ee04-4b48-4cf4-a0ce-5c412d6d4e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero finale di colonne/feature per l'ML: 740\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Riempi i NaN in productDisplayName per evitare errori\n",
    "df_encoded['productDisplayName'] = df_encoded['productDisplayName'].fillna('')\n",
    "\n",
    "# Inizializza il vettorizzatore TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500) # Limita a 500 parole più comuni/importanti\n",
    "\n",
    "# Adatta e trasforma i nomi dei prodotti\n",
    "tfidf_matrix = tfidf.fit_transform(df_encoded['productDisplayName'])\n",
    "\n",
    "# Converti la matrice TF-IDF in un DataFrame per unirla al DataFrame principale\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out(), index=df_encoded.index)\n",
    "\n",
    "# Unisci le feature TF-IDF al DataFrame codificato\n",
    "df_final = pd.concat([df_encoded.drop(columns=['productDisplayName', 'id']), tfidf_df], axis=1)\n",
    "\n",
    "print(f\"\\nNumero finale di colonne/feature per l'ML: {len(df_final.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb75d690-103a-4f7b-8314-b4a04f527334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione Training Set (X_train): (35518, 739)\n",
      "Dimensione Testing Set (X_test): (8880, 739)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Preparazione della Variabile Target (Y)\n",
    "# Il modello ML vuole numeri, non stringhe. Usiamo LabelEncoder.\n",
    "\n",
    "# Rimuovi la colonna masterCategory dal DataFrame finale prima di codificarla\n",
    "Y_text = df_final['masterCategory']\n",
    "\n",
    "# Codifica Y_text (es. 'Apparel' -> 0, 'Accessories' -> 1)\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y_text) \n",
    "\n",
    "# 2. Preparazione delle Feature (X)\n",
    "# Tutte le colonne rimanenti sono le nostre feature numeriche (incluse quelle One-Hot e TF-IDF)\n",
    "X = df_final.drop(columns=['masterCategory']) \n",
    "\n",
    "\n",
    "# 3. Suddivisione Training/Testing (80% Training, 20% Testing)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, \n",
    "    Y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=Y # Mantiene le proporzioni dello sbilanciamento del target in entrambi i set\n",
    ")\n",
    "\n",
    "print(f\"Dimensione Training Set (X_train): {X_train.shape}\")\n",
    "print(f\"Dimensione Testing Set (X_test): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fee8dae-40bd-49ae-8684-d47162dc90db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inizio addestramento del Random Forest...\n",
      "Addestramento completato.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Inizializza il modello\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "print(\"\\nInizio addestramento del Random Forest...\")\n",
    "# Addestra il modello sul set di Training\n",
    "rf_model.fit(X_train, Y_train)\n",
    "print(\"Addestramento completato.\")\n",
    "\n",
    "# Previsione sul set di Testing\n",
    "Y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0615b25-30a2-4944-ac12-c15761adbd58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Generale del Modello: 0.9998\n",
      "\n",
      "--- Report di Classificazione per Categoria ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Accessories       1.00      1.00      1.00      2255\n",
      "      Apparel       1.00      1.00      1.00      4279\n",
      "     Footwear       1.00      1.00      1.00      1844\n",
      "   Free Items       1.00      1.00      1.00        21\n",
      "Personal Care       1.00      1.00      1.00       481\n",
      "\n",
      "     accuracy                           1.00      8880\n",
      "    macro avg       1.00      1.00      1.00      8880\n",
      " weighted avg       1.00      1.00      1.00      8880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcola l'Accuracy\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"\\nAccuracy Generale del Modello: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# 2. Report Completo di Classificazione\n",
    "# Riconverti i codici numerici del target nei nomi delle categorie per un report leggibile\n",
    "target_names = le.classes_ \n",
    "\n",
    "print(\"\\n--- Report di Classificazione per Categoria ---\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=target_names))\n",
    "\n",
    "# 3. Matrice di Confusione (visualizzazione grafica)\n",
    "# Per il portfolio è essenziale! \n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# (Codice per visualizzare la matrice con Matplotlib/Seaborn da aggiungere al Notebook)\n",
    "# Ad esempio:\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee85fa83-cf77-47fe-a7fd-f7c69c5dbaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello salvato localmente.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_model, 'category_classifier.joblib')\n",
    "print(\"Modello salvato localmente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065ca166-197c-47e9-ba4e-590394d7e2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio il caricamento del modello category_classifier.joblib in GCS...\n",
      "✅ SUCCESS: Modello caricato su gs://data-science-project-luca-october-2025/models/category_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import joblib \n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "BUCKET_NAME = \"data-science-project-luca-october-2025\"  # Il tuo bucket GCS\n",
    "MODEL_FILENAME = 'category_classifier.joblib'          # Il nome del file salvato\n",
    "GCS_MODEL_PATH = \"models/category_classifier.joblib\"    # Il percorso dove lo salverai nel bucket\n",
    "# ----------------------\n",
    "\n",
    "def upload_model_to_gcs(bucket_name, source_file, destination_blob):\n",
    "    \"\"\"Carica l'artefatto (modello) sul bucket GCS.\"\"\"\n",
    "    print(f\"Inizio il caricamento del modello {source_file} in GCS...\")\n",
    "    try:\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob)\n",
    "        \n",
    "        # Carica il modello\n",
    "        blob.upload_from_filename(source_file)\n",
    "        \n",
    "        print(f\"✅ SUCCESS: Modello caricato su gs://{bucket_name}/{destination_blob}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE durante il caricamento GCS del modello: {e}\")\n",
    "\n",
    "# Esecuzione del caricamento\n",
    "if __name__ == \"__main__\":\n",
    "    upload_model_to_gcs(\n",
    "        BUCKET_NAME, \n",
    "        MODEL_FILENAME, \n",
    "        GCS_MODEL_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4846da-4ba9-4ac5-a4b0-cb9ac41518f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio il caricamento del DataFrame in BigQuery: ecommerce_data.product_features_for_ml\n",
      "✅ SUCCESS: Dati puliti e pronti per l'ML caricati in BigQuery.\n",
      "44398 righe caricate.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "DATASET_ID = \"ecommerce_data\"  \n",
    "TABLE_ID = \"product_features_for_ml\" \n",
    "# ----------------------\n",
    "\n",
    "# 1. Crea il client BigQuery\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "# 2. Definisci il riferimento alla Tabella\n",
    "table_ref = bq_client.dataset(DATASET_ID).table(TABLE_ID)\n",
    "\n",
    "# 3. Configurazione del job di caricamento (SOLO LE OPZIONI DI SCRITTURA)\n",
    "# Non includiamo 'destination' qui!\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  # Solo l'opzione di scrittura\n",
    ")\n",
    "\n",
    "# 4. Avvia il job di caricamento\n",
    "# La destinazione (table_ref) è il SECONDO argomento del metodo\n",
    "print(f\"Inizio il caricamento del DataFrame in BigQuery: {DATASET_ID}.{TABLE_ID}\")\n",
    "\n",
    "job = bq_client.load_table_from_dataframe(\n",
    "    df_save,           # 1° argomento: il DataFrame da caricare\n",
    "    table_ref,         # 2° argomento: la destinazione (risolve l'errore!)\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "job.result()  # Attendi la fine del job\n",
    "\n",
    "print(f\"✅ SUCCESS: Dati puliti e pronti per l'ML caricati in BigQuery.\")\n",
    "print(f\"{job.output_rows} righe caricate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5d047-bd29-4d22-a0f7-1cc2d3571dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
